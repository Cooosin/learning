### 海量数据在高并发场景中精准下发

#### 背景：

- 作为中台，需要下发计算商品禁配解禁后的结果给多个下游系统；

#### 挑战：

1. 结果实时性要求极高：因此要求计算结果速度快，支持量大，下发结果快+准
2. 下发的量大，可能瞬时有百万数据需要下发
3. 下游系统多：需要下发结果到9个系统

#### 业务计算下发链路

（这里为方便赘述简化了部分由于业务逻辑所设计的步骤，只保留了与下发相关的关键步骤）

1. 通过**xxl-job**定时任务去定时拉取数据库中未处理的单据(**每5秒执行一次**)
2. 调度跑单服务将禁配解禁单据解析计算到具体落到的sku、门店/仓库，原因代码（**此处结果存放到临时表中，因为一次解析的数据可能上百万甚至千万**）
3. 依据临时表和`原因表`去插入`禁配解禁日志表`（以下简称log表），该表记录着某个sku在某个门店的所有禁/解售、配、采的记录
4. 依据`原因表`等几个表去更新`禁配解禁结果表`(以下简称result表)，该表记录着某个sku在某个门店的禁售、禁配、禁采情况
5. 通过xxl-job定时任务去进行每个系统的数据下发
6. 下发服务根据**每个系统对应的日志消费水位**去拉取**指定数量**的日志（下游消费数据有限，防止打穿下游），将日志对应的操作记录下发给下游

- 这里是初步设计方案核心步骤

#### 问题&优化

1. ##### 问题：下发的数据对下游来说可能会有延迟性，导致没有下发到最新的数据

   - ###### 原因：当某一个单产生了100w条禁配的数据，下游需要时间去消费这大量数据，比如下游每分钟只能消费10w数据，那么需要10分钟才能把这些数据消费完。而在这十分钟内可能会产生对同一个sku又产生一条解禁的数据，**如果这时候还下发日志表里的禁配数据**，那其实是不正确的，因为最新的数据其实已经是解禁了。

   - ###### 优化：根据消费水位先从日志表拿到需要下发的**指定数量的日志记录**，然后根据sku和门店/仓库去result查最新的数据去进行下发

   ```sql
   select * from result where sku=#{sku} and store = #{store};
   ```

   - ###### 思考：为什么不直接从result表直接拿数据下发？

     1. 目前日志表是根据logIndex去进行增量下发，比如每次下发1w条记录的数据，logindex是个自动递增的主键，根据上一次的消费水位取`大于`该logindex的数据，可以精准的控制每一次下发的数量

     ```sql
     //取某个系统上次的消费水位
     select logIndex from log_index where system='下发的系统名称';
     //取出10000条数据进行下发
     select sku,store,id from log where id >logIndex limit 10000
     ```

     2. 如果通过result表下发会有以下问题：
        - 只能通过`最后修改时间`去进行下发，即使时间是精确到毫秒，但有可能某一毫秒产生了10w条数据，这个下发的量会失去控制。比如每次增量下发10秒的数据，有时候可能10秒只有几条数据，有时候会有100w条数据，这个时间很难把控。

2. ##### 问题：并发场景下数据可见性问题导致可能下发错误数据

   - ###### 原因：由于需要先插入log表再更新result表，而下发任务是通过log表驱动去找result表的数据去进行下发，会存在时序性问题：

     - 跑单任务A 在`12:00:01`插入了log表的数据，下发任务B在`12:00:02`去获取log表的数据，获取到了A刚插入的数据，然后根据log表去result拿到禁售禁配的数据(此时拿到的是旧数据)，而A在`12:00:03`才将结果表更新最新的，**这个时候就下发了错误的数据，但是却认为已经下发了最新的**

   - 优化：在通过logIndex同步的基础上，再通过时间去进行判断：

     ```sql
     //增加时间的限制条件，防止读到未处理完的数据
     select sku,store,id from log where id > logIndex and created_time <='xxx' limit 10000
     
     //获取当前时间
     select now()
     ```

     **该时间是跑单任务更新完result表后，获取`数据库的时间`然后往redis插入的时间戳**(`避免程序和数据库的时钟不一致！`)。在下发任务取数的时候再获取该时间戳去进行日志的查找。



#### 线上偶发问题

问题：还是遇到了下发数据不准确的问题。。将下发水位调到之前的位置再次下发，数据就是准确的了。于是还是朝着可见行的问题去排查问题

原因：最后通过看log数据和result表的更新时间和看代码发现，原来从数据库中拿到的时间是**秒级的时间，而不是毫秒时间戳**，问题就出现在这里，下面复现一下问题：

1. 在`00:00:01`跑A单完成，redis插入当前数据库时间`00:00:01`
2. 刚好达到下一个定时任务的启动时间，拿到分布式锁，在`00:00:01`跑B单并插入log表
3. 这个时候下发任务拿到redis中的数据库时间`00:00:01`,并根据这个时间和水位去拿log表的数据，再根据log表去拿result表的数据，这个时候将数据下发
4. B单的跑单任务在`00:00:02`之后才更新**result表**，于是导致下发了错误的数据

本质原因是因为使用了秒级的时间，导致了在极端情况下会有这种情况的发生

解决办法：重新把水位重置到该时间点之前，再下发一次数据。本质上正常单需要计算、解析的时间也会超过一秒，发生这种概率的事情也是极小。

思考：如何从根原上解决

- 我们数据库使用的是阿里云的ADB，本质还是得数据库支持返回毫秒级的时间最优
- 跑单/更新log表前从log表拿一下redis的数据，如果在同一秒，则等一秒再执行log表的插入